{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Selenium FR- Assignment - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It helps to automates the webpage we use it here for web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\stead\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\stead\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from bs4) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\stead\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from requests) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\stead\\anaconda3\\lib\\site-packages (from requests) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in“Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "    \n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "\n",
    "3. Then click the search button.\n",
    "\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the drivers and URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "#enter the details in the search column\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#enter the job title and location \n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list for storing the data\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr Manager I - Data Analyst (MINT)',\n",
       " 'Data Analyst (SQL, Excel, R/Python, Dashboards, PowerBI) - Contract',\n",
       " 'Specialist I / II Data Analyst',\n",
       " 'Data Analyst with Marketing Analytics-Capco',\n",
       " 'Inviting Business Analyst –Data Science and Insights Bangalore',\n",
       " 'Junior Data Analyst',\n",
       " 'SAS Data Analyst',\n",
       " 'Associate - Data Analyst ( Growth)',\n",
       " 'Associate - Data Analyst - Category Solutions',\n",
       " 'Sr. Data Analyst',\n",
       " 'Sr Manager I Data Analyst (MINT)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the job tile\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru(Devalapur)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Ulsoor)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the job location\n",
    "\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Super India Tech Mark',\n",
       " 'tech mahindra ltd',\n",
       " 'CONDUENT BUSINESS SERVICES INDIA LLP',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'WEIWO Communication Pvt. Ltd.',\n",
       " 'Cerner',\n",
       " 'Cerner Corporation',\n",
       " 'ExecBoardinAsia',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Philips India Limited',\n",
       " 'Capco Technologies Pvt Ltd',\n",
       " 'GENPACT India Private Limited',\n",
       " 'Happy Marketer Private Ltd',\n",
       " 'Diverse Lynx',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Appmocx',\n",
       " 'Walmart Labs']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the company name\n",
    "\n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-2 Yrs',\n",
       " '1,25,000 - 2,25,000 PA.',\n",
       " 'Bangalore/Bengaluru(Devalapur)',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-2 Yrs',\n",
       " '4,50,000 - 5,00,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '2-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru(Ulsoor)',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '11-15 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-5 Yrs',\n",
       " '5,50,000 - 6,50,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-9 Yrs',\n",
       " '7,00,000 - 17,00,000 PA.',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " '0-4 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-3 Yrs',\n",
       " '3,00,000 - 7,00,000 PA.',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " '2-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '2-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '10-15 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the exoerience required\n",
    "\n",
    "experience=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')\n",
    "for i in experience:\n",
    "    experience_required.append(i.text)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 60\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>1,25,000 - 2,25,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>4,50,000 - 5,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner Corporation</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Manager I - Data Analyst (MINT)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ExecBoardinAsia</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst (SQL, Excel, R/Python, Dashboards...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Specialist I / II Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst with Marketing Analytics-Capco</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inviting Business Analyst –Data Science and In...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Happy Marketer Private Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                                        Data Analyst   \n",
       "1                                        Data Analyst   \n",
       "2                                        Data Analyst   \n",
       "3                                        Data Analyst   \n",
       "4                                        Data Analyst   \n",
       "5                                        Data Analyst   \n",
       "6                                        Data Analyst   \n",
       "7                                 Senior Data Analyst   \n",
       "8                                 Senior Data Analyst   \n",
       "9                  Sr Manager I - Data Analyst (MINT)   \n",
       "10  Data Analyst (SQL, Excel, R/Python, Dashboards...   \n",
       "11                     Specialist I / II Data Analyst   \n",
       "12        Data Analyst with Marketing Analytics-Capco   \n",
       "13  Inviting Business Analyst –Data Science and In...   \n",
       "14                                Junior Data Analyst   \n",
       "\n",
       "                               Job Location  \\\n",
       "0            Bangalore/Bengaluru(Devalapur)   \n",
       "1                       Bangalore/Bengaluru   \n",
       "2                       Bangalore/Bengaluru   \n",
       "3                       Bangalore/Bengaluru   \n",
       "4                       Bangalore/Bengaluru   \n",
       "5                       Bangalore/Bengaluru   \n",
       "6               Bangalore/Bengaluru(Ulsoor)   \n",
       "7                       Bangalore/Bengaluru   \n",
       "8                       Bangalore/Bengaluru   \n",
       "9                       Bangalore/Bengaluru   \n",
       "10                      Bangalore/Bengaluru   \n",
       "11                      Bangalore/Bengaluru   \n",
       "12                Pune, Bangalore/Bengaluru   \n",
       "13                      Bangalore/Bengaluru   \n",
       "14  Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                               Company Name             Experience Required  \n",
       "0                     Super India Tech Mark                         0-2 Yrs  \n",
       "1                         tech mahindra ltd         1,25,000 - 2,25,000 PA.  \n",
       "2      CONDUENT BUSINESS SERVICES INDIA LLP  Bangalore/Bengaluru(Devalapur)  \n",
       "3   GlaxoSmithKline Pharmaceuticals Limited                         4-8 Yrs  \n",
       "4                  Myntra Designs Pvt. Ltd.                   Not disclosed  \n",
       "5                  Myntra Designs Pvt. Ltd.             Bangalore/Bengaluru  \n",
       "6             WEIWO Communication Pvt. Ltd.                         1-2 Yrs  \n",
       "7                                    Cerner         4,50,000 - 5,00,000 PA.  \n",
       "8                        Cerner Corporation             Bangalore/Bengaluru  \n",
       "9                           ExecBoardinAsia                         2-7 Yrs  \n",
       "10        Flipkart Internet Private Limited                   Not disclosed  \n",
       "11                    Philips India Limited             Bangalore/Bengaluru  \n",
       "12               Capco Technologies Pvt Ltd                         3-6 Yrs  \n",
       "13            GENPACT India Private Limited                   Not disclosed  \n",
       "14               Happy Marketer Private Ltd             Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame for data\n",
    "\n",
    "data_analyst_jobs=pd.DataFrame({})\n",
    "data_analyst_jobs['Job Title']=job_title[0:15]    \n",
    "data_analyst_jobs['Job Location']=job_location[0:15]\n",
    "data_analyst_jobs['Company Name']=company_name[0:15]\n",
    "data_analyst_jobs['Experience Required']=experience_required[0:15]\n",
    "data_analyst_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the drivers and URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "#navigate to search column\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#enter the job title and location\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list for storing the data\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Opportunity For Data Scientist Internship - Bengaluru',\n",
       " 'Data Scientist/ Analyst',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist || Data Analyst || Data science',\n",
       " 'DBCG IND - GAMMA Senior Data Scientist',\n",
       " 'Data Scientist/Senior Data Scientist',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Global Medical Data Scientist',\n",
       " 'Associate Data Scientist - CRM & Loyalty',\n",
       " 'Data Scientist/Data Analyst-immediate',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Jr. Data Scientist',\n",
       " 'Senior Data Scientist (Machine Vision solutions)',\n",
       " 'Data Scientist - BFSI',\n",
       " 'Senior Data Scientist/Manager Data Scientist',\n",
       " 'Excellent Opportunity Of Data Scientist For CMMI Level 5 Company',\n",
       " 'Job Opening For the Position Data Scientist',\n",
       " 'Data Scientist- NIIT ltd.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the job tile\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Navi Mumbai, Bangalore/Bengaluru',\n",
       " 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Sector 1 HSR Layout)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Noida, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the job location\n",
    "\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CronJ IT Technologies Private Limited',\n",
       " 'Corner Stone Solutions',\n",
       " 'Becton Dickinson India Pvt. Ltd',\n",
       " 'AugmatrixGo',\n",
       " 'Inspiration Manpower Consultancy Pvt. Ltd.',\n",
       " 'Boston Consulting Group',\n",
       " 'GANIT BUSINESS SOLUTIONS PRIVATE LIMITED',\n",
       " 'CES Ltd.',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'Inflexion Analytix Private Limited',\n",
       " 'DUN & BRADSTREET INFORMATION SERVICES INDIA PRIVATE LIMITED',\n",
       " 'Redcan IT Services LLP',\n",
       " 'Multi Recruit',\n",
       " 'ONX Software Systems Pvt Ltd',\n",
       " 'Black Turtle India Pvt Ltd',\n",
       " 'Novitas Infotech',\n",
       " 'Skyleaf Consultants',\n",
       " 'Pluto seven business solutions (p) limited',\n",
       " 'NIIT Ltd.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the company name\n",
    "\n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description\\nResponsibilities and Duties\\nCreate innovative solutions using data across sales, health care and related fields for building object detection models, classification models, recommendation engine, sentiment analysis etc.\\nFamiliarity with deep learning algorithms and frameworks like TensorFlow, Pytorch, Keras.\\nGood to go with NLP and NLTK\\nDay-to-day responsibilities include use, customize and create algorithms/models for specific tasks in data science.\\nGet exposed to and work on cutting-edge products based on ML and AI to create innovative industry solutions.\\nWork on real-life projects involving Computer Vision, NLP and other AI techniques,\\nUsing innovative ideas to collect, curate or synthesize data.\\nModel the problem into an ML/DL framework.\\nDeploy models to real time staging servers.\\nFlexibility in working independently and do needful research whenever required.\\nRequired Experience, Skills and Qualifications\\nKnowledge of Python\\nKnowledge in libraries like OpenCV, Scikit Learn, NumPy etc.\\nScripting\\nUnderstanding of different frameworks like Pytorch, TensorFlow, Keras etc.\\nKnowledge on NLP\\nGood Knowledge on OOP and programing in python adapting to requirement\\nUnderstanding of AWS.\\nUnderstanding of any annotation tool.\\nAbility to write robust and testable code.\\nStrong knowledge in computer science fundamentals, algorithms, mathematics, linear algebra, probability and statistics.\\nStrong communication skills.\\nAn analytical mind with problem-solving abilities.\\nDegree in Computer Science, Mathematics, Computational Linguistics or similar field.\\nRoleTrainee\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nTensorflowJavaC++CphythonData StructuresArtificial IntelligenceMachine LearningMATLABsoftware DeveloperNLPAlgorithmsFresherComputer VisionLinear Algebra',\n",
       " 'Job description\\nLocation - Bangalore / Bengaluru\\nDuration- 6 Months\\nResponsibilities and Duties\\nCreate innovative solutions using data across sales, health care and related fields for building object detection models, chatbots, classification models etc.\\nFamiliarity with deep learning algorithms and frameworks like Pytorch, Keras, TensorFlow.\\nGood to go with NLP and NLTK\\nDay-to-day responsibilities include use, customize and create algorithms for specific tasks in data science.\\nGet exposed to and work on cutting-edge products based on ML and AI to create innovative industry solutions..\\nWork on real-life projects involving Computer Vision, NLP and other AI techniques,\\nUsing innovative ideas to collect, curate or synthesize data.\\nModel the problem into an ML/DL framework.\\nDeploy models to real time staging servers.\\nFlexibility in working independently and do needful research whenever required.\\nRequired Experience, Skills and Qualifications\\nKnowledge of Python\\nKnowledge in libraries like OpenCV, Scikit Learn, NumPy etc.\\nUnderstanding of different frameworks like Pytorch, TensorFlow, Keras etc.\\nKnowledge on NLP\\nGood Knowledge on OOP and programing in python adapting to requirement\\nUnderstanding of aws\\nUnderstanding of any annotation tool\\nAbility to write robust and testable code.\\nStrong knowledge in computer science fundamentals, algorithms, mathematics, linear algebra, probability and statistics.\\nStrong communication skills.\\nAn analytical mind with problem-solving abilities.\\nDegree in Computer Science, Mathematics, Computational Linguistics or similar field.\\nQualification:\\n\\nLooking for IIT, IIIT IISc, NIT, BIT & Equivalent colleges (Preferred)\\nRoleSoftware Developer\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nKey Skills\\nNLPOpencvArtificial Intelligence\\nData ScienceRtensorflowAlgorithmsMATLABLinear AlgebraPython\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nRoles and Responsibilities\\nob Description Summary:\\nAs a member of the BD Advanced Analytics team, the Data Scientist role will collect, interpret, and deploy predictive analytics and machine learning models to assist our business partners in delivering advanced data analytics solutions to address key strategic business initiatives. The primary focus being the development and deployment of actionable insights that have a positive impact on BD’s business operations.\\nJob Description:\\nEvaluating business requirements and developing compelling user stories in collaboration with business stakeholders across various functions and regions\\nCollecting, interpreting, preparing and modelling data to provide actionable insights\\nPrototyping advanced data analytics solutions for presentation to business partners and stakeholders\\nApplying predictive analytics and machine learning methods and techniques appropriately to address business requirements\\nProvide expertise to guide business stakeholders in identifying opportunities for the use of BD’s data assets for the purpose of advanced data analytics\\nWork closely with data engineering and DataOps peers to productionalize advanced data analytics use cases\\nQualifications\\nMaster’s degree in STEM field or equivalent demonstrated work experience\\nExperience with Python, R, Hadoop, HIVE, SPARK, Jupyter and related advanced analytics / machine learning libraries (Scikitlearn, Tensorflow, Keras, )\\nMinimum 2 years of relevant work experience\\nAbility to translate complex solutions to a non-technical audience (storytelling & visualization)\\nExpertise in machine learning, neural networks, clustering, classification, regression and other common advanced analytics methods and techniques\\nMature competency for critical thinking, problem solving, working with ambiguity, communications and collaboration\\nPreferred\\nExperience with technologies related to data preparation, processing & optimization (e.g. Azure, HQL, SPARK SQL)\\nExperience with data visualization tools (Power BI)\\nFlexibility to accommodate meetings with international stakeholders in their respective time-zone\\n\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - eCommerce, Internet Technologies\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nRHiveHadoopData AnalyticsMachine LearningPythonPredictive Analytics',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\n\\n- Selecting features, building and optimizing classifiers using machine learning techniques\\n\\n- Data mining using state-of-the-art methods\\n\\n- Enhancing data collection procedures to include information that is relevant for building analytic systems\\n\\n- Processing, cleansing, and verifying the integrity of data used for analysis\\n\\n- Doing ad-hoc analysis and presenting results in a clear manner\\n\\n- Creating automated anomaly detection systems and constant tracking of its performance\\n\\nSkills Required :\\n\\n- Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n\\n- Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc\\n\\n- Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization\\n\\n- 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks\\n\\n- Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable\\n\\n- Proficiency in using query languages such as SQL, Hive, Pig\\n\\n- Good applied statistics skills, such as distributions, statistical testing, regression, etc.\\n\\n- Good scripting and programming skills\\n\\n- Data-oriented personality\\n\\n- B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITS\\nRoleData Analyst\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nHiveRCloud ComputingData ScientistComputer VisionMachine LearningDeep LearningSQLPig',\n",
       " 'Job description\\nJob description\\nJob Summary and Key Responsibilities\\nManage, architect, and analyze big data to build data driven business insights and high impact data models to generate significant business value. Create models and processes to collect, distill and interpret data with a view to aid better, more informed decision making. Examine and explore data from multiple disparate sources with the goal of discovering insights which in turn can provide competitive advantage for our stakeholders.\\nThe role involves but not limited to the following:\\nCreate insights from predictive statistical modeling, mathematical knowledge, tools, and techniques to solve complex problems and deliver value\\nCollaborate with Accenture teams to address business issues and influence change using strategy, industry, and analytical skills\\nDeliver large-scale programs that integrate processes with technology to help clients achieve high performance\\nMining and EDA of large datasets to assist in developing analytics solution\\nIndividual contributor and/or oversees a small work effort\\nWork with minimal supervision on daily tasks and moderate level of instruction on new assignments\\nKey Skills\\nMust Have\\nAnalytical skills\\nKnowledge of statistical techniques and machine learning algorithms\\nKnowledge of analysis tools like R, Python\\nAdvanced Excel, PowerPoint skills\\nAdvanced communication (written and oral) and strong interpersonal skills\\nAbility to work cross-culturally\\nGood to have\\nKnowledge on Google Cloud Platform\\nHuman Resources experience\\nAdditional Accenture HR systems experience\\nUnderstanding of Text analysis, VBA, Java, Python, .Net and visualization tools like Qliksense, Qlikview, Tableau will be an added advantage\\nInterested Candidates\\n\\n\\nPlease Contact: Geethanjali\\n9900044693\\nhr1@inspirationmanpower.co.in\\n\\nRoleData Analyst\\nIndustry TypeBPO, Call Centre, ITeS\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nData ScienceJavaREDAStatistical ModelingData AnalysisBig DataTableauMachine LearningPython',\n",
       " 'Job description\\n    What Youll Do\\n\\nWe re looking for a passionate and talented Senior Data Scientist to join our rapidly growing team.\\nIn this role, you ll have the chance to roll up your sleeves and apply data science methods and analytics to real-world business situations across a variety of industries.\\nAs the field of advanced analytics is rapidly evolving, the SDS is responsible for staying current on leading-edge business applications, tools and approaches, proactively working with the Analytics Leadership to enhance offerings that\\ndeliver competitive advantage to BCG.\\nSuccessful candidates are intellectually curious builders who are biased toward action, scrappy, and communicative.\\nYou will also get the chance to travel: we have clients across the globe Make sure your passport is ready to go!\\n \\n\\n\\nWHO YOU ARE. YOU:\\nHave deep technical and Data Science expertise: The successful candidate will have a wealth of experience with applying advanced analytics to a variety of business situations, such that they can efficiently and effectively advise multiple teams on the best path to uncovering critical insights for clients.\\nAre an autonomous self-starter with a passion for analytics and problem solving. You will help build new Analytics service offerings that grow our portfolio of products and will captures proprietary content, and support the creation of proposal/selling documents.\\nAre comfortable managing engagements, client relationships, and acting as a thought Leader. Strong presence, strong collaborator and leadership skills and ability to operate effectively in a matrix organization are a must.\\nLove building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience)\\nHave significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data; as well as a deep understanding of modern machine learning techniques and their mathematical underpinnings, and are able to translate this into business implications for our clients\\nHave strong project management skills\\nMaster s Degree with significant relevant experience providing advanced analytics solutions, or relevant PhD in computer science, applied mathematics, statistics, machine learning, or a related data centric field.\\nDemonstrated deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.\\nStrong record of professional accomplishment and leadership.\\nFluency in at least one scripting language (e.g. Python, R)\\nFluency in English and local office language are required\\nFast-paced, intellectually intense, service-oriented environment\\nPosition is located in either Chennai, Mumbai, Delhi-NCR or Bengaluru\\nExpect up to 60-80% of time spent traveling\\nRoleSoftware Developer\\nIndustry TypeStrategy, Management Consulting Firms\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nComputer scienceadvanced analyticsSDSdata scienceArtificial IntelligenceProject managementMachine learningManagement consultingBusiness strategyPython',\n",
       " 'Job description\\n\\nAbout Ganit Inc\\n\\nFounded by senior industry experts, Ganit is the fastest-growing data science company in Chennai with offices in Bengaluru, Mumbai & New Jersey.\\nGanit has flipped the data science value chain as we do not start with a technique but for us, consumption comes first. With this philosophy, we have successfully scaled from being a small start-up to a 200 resource company with clients in the US, Singapore, Africa, UAE, and India.\\nWe are looking for experienced data enthusiasts who can make the data talk to them.\\n\\nWhat you will be doing.\\n\\nUnderstand business problems and translate business requirements into technical requirements.\\n\\nConduct complex data analysis to ensure data quality & reliability i.e., make the data talk by extracting, preparing, and transforming it.\\n\\nIdentify, develop and implement statistical techniques and algorithms to address business challenges and add value to the organization.\\n\\nGather requirements and communicate findings in the form of a meaningful story with the Stakeholders.\\n\\nBuild & implement data models using predictive modeling techniques. Interact with clients and provide support for queries and delivery adoption.\\n\\nLead and mentor data analysts.\\n\\nWhat we are looking for:\\nApart from your love for data and ability to code even while sleeping you would need the following.\\n\\nMinimum of 04 years of experience in designing and delivery of data science solutions.\\n\\nYou should have successful projects in Manufacturing in your kitty to show-off. (Experience on manufacturing analytics is a MUST)\\n\\nDeep understanding of various statistical techniques, mathematical models, and algorithms to start the conversation with the data in hand.\\n\\nAbility to choose the right model for the data and translate that into a code using R, Python, VBA, SQL, etc.\\n\\nBachelors/Masters degree in Engineering/Technology or\\nMBA from Tier-1 B School or\\nMSc. in Statistics or Mathematics\\n\\nWhat is in it for you:\\n\\nBe a part of building the biggest brand in Data science.\\nAn opportunity to be a part of a young and energetic team with a strong pedigree.\\nWork on awesome projects across industries and learn from the best in the industry, while growing at a hyper rate.\\nRoleData Analyst\\nIndustry TypeAutomobile, Auto Anciliary, Auto Components\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nPredictive ModelingManufacturing AnalyticsPython\\nData ScienceRData QualityAlgorithmsVBAData AnalysisAnamoly detectionStatisticsSQL\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\nMust have strong Python Programming Skills\\nStrong analytical & algorithm development skills\\nLogical and Analytical skills must be really strong\\nMust have worked in DeepLearning Efforts - Especially computer vision.\\nMust have experinece with Object Detection - Custom model training for Object detection\\nShould have experience with atleast one or more of these - Tensorflow, Keras, PyTorch\\n\\nPrimary Skills - Python + tensorflow - Keras / PyTorch, OpenCV\\nPerks and Benefits\\n\\nKindly share your resume to kandavelkumar.lakshmanan @cesltd.com\\n\\nRoleTechnical Architect\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nTensorflowObject DetectionAlgorithm DevelopmentAnalytical SkillsProgrammingMachine LearningDeep LearningPytorchData ScienceROpencvKerasComputer VisionPython',\n",
       " 'Not Available',\n",
       " 'Job description\\nThe Role\\nGeneral Position Definition\\nThis role will drive analytics and insights for the Global CRM & Loyalty teams\\nThe ideal candidate is passionate about customer analytics - specifically CRM and Loyalty\\nThe candidate will have strong quantitative skills (like statistics, mathematics, machine learning) and has applied those skills in solving real world problems in marketing\\nIncumbent is responsible for working on a range of technologies and tools collaborating directly with the marketing stakeholders & other partners\\nPurpose\\nLeverage analytics, data and deep customer insights to identify and execute innovative programs that continually push CRM initiatives to the next level\\nBuild and maintain a test and learn roadmap (A/B Testing) and work to continually iterate and optimize CRM efforts in order to increase the effectiveness of all channels\\nMeasure impact of customer engagement initiatives across all channels (email, SMS, push notifications, direct mail, etc.) and optimize campaign spends\\nSupport development of the contact strategy with ad-hoc analysis and projects.\\nSupport design and development of CRM reporting dashboards; establish templates and processes for regularly sharing out CRM progress and results with key stakeholders\\nDevelop and evolve advanced segmentation strategies for targeted campaigns driving incremental revenues\\nSkills\\nIndustry / Functional Expertise\\nProvide deep business expertise in:CRM, Loyalty Analytics: Strong Campaign Analytics experience in both online & offline. Must have worked with Campaign, Loyalty and CRM data. Understands campaign effectiveness study and experienced in planning/targeting for CRM activities based on learning from previous activities\\nMarketing / Customer Analytics: Campaign design and effectiveness testing, churn prediction, cross-sell / up-sell, Market Basket Analysis, Customer segmentation, propensity analysis, customer lifetime value\\nPreferably worked in the past in Retail companies\\nPaid Media Experience is also preferable and will be an added advantage\\nProficiency Level: Mastery\\nStakeholder Engagement Skills\\nWorking collaboratively across multiple sets of stakeholders – business SMEs, IT, Data teams, Analytics resources, etc. to deliver on project deliverables and tasks\\nIdentify actionable insights that directly address marketing challenges / opportunities\\nArticulate business insights and recommendations (based on model output) to respective stakeholders\\nUnderstanding business KPIs, frameworks and drivers for performance\\nProficiency Level: Mastery\\nTechnology Skills\\nExperience in specialized analytics tools and technologies (including, but not limited to)Azure Databricks, Alteryx\\nPower BI, Spotfire or other visualization tools\\nPython, R\\nAdobe Analytics (good to have)\\nStatistics / Mathematics: Data Quality Analysis, Data identification, Hypothesis testing, Univariate / Multivariate Analysis, Cluster Analysis, Classification/PCA, Factor Analysis, Linear Modeling, Affinity & Association, Time Series\\nIdentify the right approach(es) for given scenario and articulate why the approach fits\\nAssess data availability and modeling feasibility\\nProficiency Level: Skill-to-Mastery\\nSpecial Challenges\\nMust have Skills:Knowledge of Direct marketing and CRM principles (segmentation, lifecycle management, etc.).\\nFamiliarity with the marketing funnel and customer journey frameworks to guide strategy.\\nEasily analyzes, draws and synthesizes important insights from complex data.\\ncurious and self-driven to understand business performance through data.\\nAbility to translate a business or marketing question into a well-defined analytical plan that includes data requirements for technical resources to extract the necessary data.\\nRapid onboarding on projects, understanding analytics goal and working with ill-defined datasets\\nCommunicating technical jargon in plain English to colleagues within Data Science team and outside\\nVirtual working with network of colleagues located throughout the globe\\nDimensions\\nSupport design and delivery of analytics projects, within Retail business unit in Shell\\nExperience\\nMinimum 3-5 years of relevant experience in Marketing / Customer Analytics\\nPreferred experience in Retail or E-commerce managing CRM and Loyalty Data\\nGood interpersonal communication skills and influencing skills\\nEagerness to learn and ability to work with limited supervision\\nAdvanced university degree in Mathematics, Statistics, Engineering, Economics, OR, etc.\\nRoleData Analyst\\nIndustry TypeChemicals, PetroChemical, Plastic, Rubber\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nDirect MarketingMultivariate AnalysisR Data ScientistFactor AnalysisCustomer AnalyticsTime SeriesMarket Basket AnalysisMachine LearningStatisticsCluster Analysis']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the detail job description\n",
    "\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"Not Available\")\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Detailed Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>Job description\\nResponsibilities and Duties\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>Job description\\nLocation - Bangalore / Bengal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Becton Dickinson India Pvt. Ltd</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>Job description\\nJob description\\nJob Summary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Job description\\n    What Youll Do\\n\\nWe re lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Job description\\n\\nAbout Ganit Inc\\n\\nFounded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Job description\\nThe Role\\nGeneral Position De...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                            Data Scientist/ Analyst   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4     Data Scientist || Data Analyst || Data science   \n",
       "5             DBCG IND - GAMMA Senior Data Scientist   \n",
       "6               Data Scientist/Senior Data Scientist   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8                      Global Medical Data Scientist   \n",
       "9           Associate Data Scientist - CRM & Loyalty   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "7  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 Company Name  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "2             Becton Dickinson India Pvt. Ltd   \n",
       "3                                 AugmatrixGo   \n",
       "4  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "5                     Boston Consulting Group   \n",
       "6    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "7                                    CES Ltd.   \n",
       "8     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "9         Shell India Markets Private Limited   \n",
       "\n",
       "                            Detailed Job Description  \n",
       "0  Job description\\nResponsibilities and Duties\\n...  \n",
       "1  Job description\\nLocation - Bangalore / Bengal...  \n",
       "2  Job description\\nRoles and Responsibilities\\no...  \n",
       "3  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "4  Job description\\nJob description\\nJob Summary ...  \n",
       "5  Job description\\n    What Youll Do\\n\\nWe re lo...  \n",
       "6  Job description\\n\\nAbout Ganit Inc\\n\\nFounded ...  \n",
       "7  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "8                                      Not Available  \n",
       "9  Job description\\nThe Role\\nGeneral Position De...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a DataFrame for our data\n",
    "\n",
    "data_scientist_jobs=pd.DataFrame({})\n",
    "data_scientist_jobs['Job Title']=job_title[0:10]    \n",
    "data_scientist_jobs['Job Location']=job_location[0:10]\n",
    "data_scientist_jobs['Company Name']=company_name[0:10]\n",
    "data_scientist_jobs['Detailed Job Description']=job_description[0:10]\n",
    "data_scientist_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "    \n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "\n",
    "3. Then click the search button.\n",
    "\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Females Required- Data Scientist- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Required- Data Scientist (NLP)-Axis Bank - 6 m...</td>\n",
       "      <td>Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...</td>\n",
       "      <td>Axis Bank Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning (IS...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Data Scientist - IBM Garage   \n",
       "1  Data Scientist/Data Analyst - Python/Machine L...   \n",
       "2            Females Required- Data Scientist- Noida   \n",
       "3         Data Scientist - Python & Machine Learning   \n",
       "4         Data Scientist - Python & Machine Learning   \n",
       "5  Data Scientist - Python / Machine Learning / T...   \n",
       "6         Data Scientist - Python & Machine Learning   \n",
       "7  Required- Data Scientist (NLP)-Axis Bank - 6 m...   \n",
       "8  Data Scientist - Python / Machine Learning / T...   \n",
       "9  Data Scientist - Python & Machine Learning (IS...   \n",
       "\n",
       "                                            Location            Company name  \\\n",
       "0  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  IBM India Pvt. Limited   \n",
       "1                                  Mumbai, Ghaziabad          Change leaders   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR                Randstad   \n",
       "3  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...     FUTURES AND CAREERS   \n",
       "4  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...     FUTURES AND CAREERS   \n",
       "5  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...     FUTURES AND CAREERS   \n",
       "6  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...     FUTURES AND CAREERS   \n",
       "7  Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...       Axis Bank Limited   \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...     FUTURES AND CAREERS   \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...     FUTURES AND CAREERS   \n",
       "\n",
       "  Experience required  \n",
       "0             5-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             3-7 Yrs  \n",
       "3             2-7 Yrs  \n",
       "4             2-7 Yrs  \n",
       "5             3-8 Yrs  \n",
       "6             2-7 Yrs  \n",
       "7             4-9 Yrs  \n",
       "8             3-8 Yrs  \n",
       "9             3-8 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling webdriver\n",
    "\n",
    "driver=webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe') \n",
    "\n",
    "#If not r, we can use executable_path = \"C:/path name\"\n",
    "#Getting the website to driver\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#Finding the required elements from the search bar of job\n",
    "job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "#Sending the input to the webpage\n",
    "job_search.send_keys(\"Data Scientist\")\n",
    "\n",
    "#Searching the input by using the search button and clicking it\n",
    "driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "\n",
    "#Locating the filters in the webpage\n",
    "#First, filter the location\n",
    "filter_location=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for i in filter_location:\n",
    "    if i.text=='Delhi / NCR':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "#Filtering the salary\n",
    "filter_salary=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for i in filter_salary:\n",
    "    if i.text=='3-6 Lakhs':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "#After filtering location and salary, specify the url of webpage\n",
    "url=\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&ctcFilter=3to6&cityTypeGid=9508\"\n",
    "driver.get(url)\n",
    "\n",
    "#Extracting all the tags having the job title\n",
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title\n",
    "\n",
    "#Extracting the text from the tags\n",
    "title=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in job_title[:10]:\n",
    "    title.append(i.text)\n",
    "title\n",
    "\n",
    "#Extracting all the tags having the job location\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "job_location\n",
    "\n",
    "#location\n",
    "location=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in job_location[:10]:\n",
    "    location.append(i.text)\n",
    "location\n",
    "\n",
    "#Extracting the tags having the company name\n",
    "name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "name\n",
    "\n",
    "#Extracting the text from the tags\n",
    "company=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in name[:10]:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "#Extracting the tags having experience required\n",
    "exp_required=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "exp_required\n",
    "\n",
    "#Extracting the text from the tags\n",
    "exp=[]  #Empty list\n",
    "\n",
    "#scrap data for the first 10 job results, we are running a for loop to first 10 results only\n",
    "for i in exp_required[:10]:\n",
    "    exp.append(i.text)\n",
    "exp\n",
    "#Checking out the length of the data extracted\n",
    "print(len(title),len(location),len(company),len(exp))\n",
    "\n",
    "#saving in dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=title\n",
    "jobs['Location']=location\n",
    "jobs['Company name']=company\n",
    "jobs['Experience required']=exp\n",
    "jobs\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "def glass_door_job(url):\n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    job_title=[]\n",
    "    company_name=[]\n",
    "    rating=[]\n",
    "    days=[]\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # If we visit the glassdoor page we will observe that, to navigate into the page we have to do the login\n",
    "    #click on the sign-in button for login in\n",
    "    driver.find_element_by_xpath('//div[@class=\"locked-home-sign-in\"]').click()\n",
    "    \n",
    "    #enter the demo login details\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('getdarjee@gmail.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('Assignment@123')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #maximize the window size because there are some text font size is will has other element details in short window\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #fill the requied details in search column and click search\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida (India)')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #search the desired detail which we hve entered\n",
    "    driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    jobs=driver.find_elements_by_xpath('//article[@id=\"MainCol\"]/div/ul/li')\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        job.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        #scrape the data\n",
    "        job_title.append((driver.find_element_by_xpath('//div[@class=\"css-1vg6q84 e1tk4kwz4\"]')).text)\n",
    "        company_name.append((driver.find_element_by_xpath('//div[@class=\"css-87uc0g e1tk4kwz1\"]')).text.replace('\\n',''))\n",
    "        try:\n",
    "            rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text)\n",
    "        except:\n",
    "            rating.append('NA')\n",
    "        try:\n",
    "            days.append((driver.find_element_by_xpath('//div[@data-test=\"job-age\"]')).text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    job_glass_door=pd.DataFrame({})\n",
    "    job_glass_door['Job Title']=job_title[0:10]\n",
    "    job_glass_door['Company Name']=company_name[0:10]\n",
    "    job_glass_door['Rating of the Company']=rating[0:10]\n",
    "    job_glass_door['Job Posted Days Ago']=days[0:10]\n",
    "    return job_glass_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Rating of the Company</th>\n",
       "      <th>Job Posted Days Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Hiring for Data Scientist Position(Exp ...</td>\n",
       "      <td>Unyscape Infocom Pvt. Ltd4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Techlive5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>Genpact3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Asquero5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Microsoft4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ESRI, Inc.3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science Internship</td>\n",
       "      <td>Accolite Software Private Limited3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Urgent Hiring for Data Scientist Position(Exp ...   \n",
       "2                                     Data Scientist   \n",
       "3                           Manager - Data Scientist   \n",
       "4                                Data Science Intern   \n",
       "5                              Data Scientist Intern   \n",
       "6                                   Data Scientist 2   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                            Data Science Internship   \n",
       "\n",
       "                           Company Name Rating of the Company  \\\n",
       "0                     Biz2Credit Inc3.8                   3.8   \n",
       "1          Unyscape Infocom Pvt. Ltd4.1                   4.1   \n",
       "2                           Techlive5.0                   5.0   \n",
       "3                            Genpact3.8                   3.8   \n",
       "4                            Asquero5.0                   5.0   \n",
       "5          Salasar New Age Technologies                    NA   \n",
       "6                          Microsoft4.4                   4.4   \n",
       "7          Salasar New Age Technologies                    NA   \n",
       "8                         ESRI, Inc.3.9                   3.9   \n",
       "9  Accolite Software Private Limited3.9                   3.9   \n",
       "\n",
       "  Job Posted Days Ago  \n",
       "0                30d+  \n",
       "1                30d+  \n",
       "2                30d+  \n",
       "3                30d+  \n",
       "4                30d+  \n",
       "5                30d+  \n",
       "6                30d+  \n",
       "7                30d+  \n",
       "8                30d+  \n",
       "9                30d+  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the Calling Function\n",
    "\n",
    "glass_door_job('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company\n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Minimum salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 5,97,967/yr</td>\n",
       "      <td>₹333K</td>\n",
       "      <td>₹1,080K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,12,243/yr</td>\n",
       "      <td>₹560K</td>\n",
       "      <td>₹2,147K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,12,741/yr</td>\n",
       "      <td>₹436K</td>\n",
       "      <td>₹11,274K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 7,37,972/yr</td>\n",
       "      <td>₹569K</td>\n",
       "      <td>₹2,648K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹ 7,15,984/yr</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,565K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 13,41,900/yr</td>\n",
       "      <td>₹1,037K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 7,90,812/yr</td>\n",
       "      <td>₹487K</td>\n",
       "      <td>₹1,421K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,81,047/yr</td>\n",
       "      <td>₹602K</td>\n",
       "      <td>₹1,644K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 9,89,924/yr</td>\n",
       "      <td>₹196K</td>\n",
       "      <td>₹1,755K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 11,73,127/yr</td>\n",
       "      <td>₹558K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Number of salaries  Average salary  \\\n",
       "0  Tata Consultancy Services        14 salaries   ₹ 5,97,967/yr   \n",
       "1                  Accenture        14 salaries  ₹ 11,12,243/yr   \n",
       "2                  Delhivery        14 salaries  ₹ 12,12,741/yr   \n",
       "3                        IBM        13 salaries   ₹ 7,37,972/yr   \n",
       "4         Ericsson-Worldwide        12 salaries   ₹ 7,15,984/yr   \n",
       "5         UnitedHealth Group        10 salaries  ₹ 13,41,900/yr   \n",
       "6         Valiance Solutions         9 salaries   ₹ 7,90,812/yr   \n",
       "7                 Innovaccer         8 salaries  ₹ 11,81,047/yr   \n",
       "8              ZS Associates         7 salaries   ₹ 9,89,924/yr   \n",
       "9                EXL Service         7 salaries  ₹ 11,73,127/yr   \n",
       "\n",
       "  Minimum salary Maximum salary  \n",
       "0          ₹333K        ₹1,080K  \n",
       "1          ₹560K        ₹2,147K  \n",
       "2          ₹436K       ₹11,274K  \n",
       "3          ₹569K        ₹2,648K  \n",
       "4          ₹350K        ₹1,565K  \n",
       "5        ₹1,037K        ₹1,500K  \n",
       "6          ₹487K        ₹1,421K  \n",
       "7          ₹602K        ₹1,644K  \n",
       "8          ₹196K        ₹1,755K  \n",
       "9          ₹558K        ₹1,500K  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call web driver\n",
    "driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "\n",
    "#website\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "\n",
    "#Finding the required elements from the search bars of job and location\n",
    "job_search=driver.find_element_by_id('KeywordSearch')\n",
    "location_search=driver.find_element_by_id('LocationSearch')\n",
    "\n",
    "#Sending the inputs to the webpage\n",
    "job_search.send_keys(\"Data Scientist\")\n",
    "location_search.send_keys(\"Noida\")\n",
    "\n",
    "#Searching the inputs by using the search button and clicking it\n",
    "driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\").click()\n",
    "\n",
    "#specify webpage from where data have to be scrapped\n",
    "url=\"https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn\"\n",
    "driver.get(url)\n",
    "\n",
    "#Extracting the tags having the company name\n",
    "comp_name=driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[2]\")\n",
    "comp_name\n",
    "\n",
    "#Extracting the text from the tags\n",
    "company=[]  #Empty list\n",
    "\n",
    "#scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in comp_name[:10]:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "#Extracting the tags having the number of salaries\n",
    "no_salaries=driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[5]\")\n",
    "no_salaries\n",
    "\n",
    "#Extracting the text from the tags\n",
    "no_of_salaries=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in no_salaries[:10]:\n",
    "    no_of_salaries.append(i.text)\n",
    "no_of_salaries\n",
    "\n",
    "#Extracting the tags having average salary\n",
    "avg_sal=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\")\n",
    "avg_sal\n",
    "\n",
    "#Extracting the text from the tags\n",
    "avg_salary=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in avg_sal[:10]:\n",
    "    avg_salary.append(i.text.replace('\\n',''))\n",
    "avg_salary\n",
    "\n",
    "#Extracting the tags having minimum salary\n",
    "min_sal=driver.find_elements_by_xpath(\"//div[@class='col-3 offset-1 d-none d-md-block']/div/div[2]/span[1]\")\n",
    "min_sal\n",
    "\n",
    "#Extracting the text from the tags\n",
    "min_salary=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in min_sal[:10]:\n",
    "    min_salary.append(i.text)\n",
    "min_salary\n",
    "\n",
    "#Extracting the tags having the maximum salary\n",
    "max_sal=driver.find_elements_by_xpath(\"//div[@class='col-3 offset-1 d-none d-md-block']/div/div[2]/span[2]\")\n",
    "max_sal\n",
    "\n",
    "#Extracting the text from the tags\n",
    "max_salary=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in max_sal[:10]:\n",
    "    max_salary.append(i.text)\n",
    "max_salary\n",
    "\n",
    "#Checking out the length of the data extracted\n",
    "print(len(company),len(no_of_salaries),len(avg_salary),len(min_salary),len(max_salary))\n",
    "\n",
    "#dataframe for saving the data\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Company Name']=company\n",
    "jobs['Number of salaries']=no_of_salaries\n",
    "jobs['Average salary']=avg_salary\n",
    "jobs['Minimum salary']=min_salary\n",
    "jobs['Maximum salary']=max_salary\n",
    "jobs\n",
    "    \n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "def flipkart_sunglasses(url):\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #search for sunglasses product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    sunglass_brand_name=[]\n",
    "    sunglass_description=[]\n",
    "    sunglass_price=[]\n",
    "    sunglass_discount=[]\n",
    "    \n",
    "    #scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sunglass_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sunglass_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sunglass_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sunglass_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    #create a DataFrame for our data   \n",
    "    sunglasses_flip=pd.DataFrame({})\n",
    "    sunglasses_flip['Product Brand']=sunglass_brand_name[:100]\n",
    "    sunglasses_flip['Product Description']=sunglass_description[:100]\n",
    "    sunglasses_flip['Price of Product']=sunglass_price[:100]\n",
    "    sunglasses_flip['Discount on Product']=sunglass_discount[:100]\n",
    "    return sunglasses_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price of Product</th>\n",
       "      <th>Discount on Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular, Over-sized Sunglass...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (60)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹569</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored, Gradient Wayfarer Sun...</td>\n",
       "      <td>₹318</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹289</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Cat-eye Sunglasses (58)</td>\n",
       "      <td>₹459</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (58)</td>\n",
       "      <td>₹493</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product Brand                                Product Description  \\\n",
       "0           PIRASO  UV Protection Rectangular, Over-sized Sunglass...   \n",
       "1           PIRASO           UV Protection Over-sized Sunglasses (60)   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "4         Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "..             ...                                                ...   \n",
       "95           NuVew  UV Protection, Mirrored, Gradient Wayfarer Sun...   \n",
       "96          GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "97  ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "98          Aislin    UV Protection, Gradient Cat-eye Sunglasses (58)   \n",
       "99          Aislin              UV Protection Cat-eye Sunglasses (58)   \n",
       "\n",
       "   Price of Product Discount on Product  \n",
       "0              ₹449             85% off  \n",
       "1              ₹179             88% off  \n",
       "2              ₹758             15% off  \n",
       "3              ₹569             28% off  \n",
       "4              ₹499             50% off  \n",
       "..              ...                 ...  \n",
       "95             ₹318             68% off  \n",
       "96             ₹289             85% off  \n",
       "97             ₹399             80% off  \n",
       "98             ₹459             69% off  \n",
       "99             ₹493             80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the Calling Function\n",
    "\n",
    "flipkart_sunglasses('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "def iphone_100_review(url):\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    #scrape the data\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "        \n",
    "        reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in reviews:\n",
    "            review_summary.append(i.text)\n",
    "        \n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        time.sleep(10)    \n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(10)\n",
    "        j+=1\n",
    "        time.sleep(10)\n",
    "    \n",
    "    #create a DataFrame for our data\n",
    "    iphone_review=pd.DataFrame({})\n",
    "    iphone_review['Rating']=rating\n",
    "    iphone_review['Review Summary']=review_summary\n",
    "    iphone_review['Full Reviews']=full_review\n",
    "    return iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*\\nDoesn't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5   Worth every penny   \n",
       "3       5       Great product   \n",
       "4       5  Highly recommended   \n",
       "..    ...                 ...   \n",
       "95      5    Perfect product!   \n",
       "96      5    Perfect product!   \n",
       "97      5           Fabulous!   \n",
       "98      5           Wonderful   \n",
       "99      5   Worth every penny   \n",
       "\n",
       "                                         Full Reviews  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "..                                                ...  \n",
       "95  It’s a must buy who is looking for an upgrade ...  \n",
       "96  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "97  This is my first iOS phone. I am very happy wi...  \n",
       "98  *Review after 10 months of usage*\\nDoesn't see...  \n",
       "99  Best budget Iphone till date ❤️ go for it guys...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the Calling Function\n",
    "\n",
    "iphone_100_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "def flip_sneakers(url):\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    #navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #search for sneaker product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    sneaker_brand_name=[]\n",
    "    sneaker_description=[]\n",
    "    sneaker_price=[]\n",
    "    sneaker_discount=[]\n",
    "    \n",
    "    #scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sneaker_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sneaker_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sneaker_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sneaker_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    #create a DataFrame for our data   \n",
    "    sneakers_flipkart=pd.DataFrame({})\n",
    "    sneakers_flipkart['Brand Name']=sneaker_brand_name[:100]\n",
    "    sneakers_flipkart['Product Descriptions']=sneaker_description[:100]\n",
    "    sneakers_flipkart['Price']=sneaker_price[:100]\n",
    "    sneakers_flipkart['Discount %']=sneaker_discount[:100]\n",
    "    return sneakers_flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extoes</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹798</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Airland</td>\n",
       "      <td>shoe Sneakers For Men</td>\n",
       "      <td>₹258</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹384</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>White Shoes For Men | Casual White Laceups Sho...</td>\n",
       "      <td>₹496</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹426</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                               Product Descriptions  \\\n",
       "0   French Connection                                   Sneakers For Men   \n",
       "1              Extoes  Modern Trendy Shoes Combo pack of 4 Sneakers F...   \n",
       "2              Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "3        Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4              Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "..                ...                                                ...   \n",
       "95            Airland                              shoe Sneakers For Men   \n",
       "96         D-SNEAKERZ  Casual , Partywear Sneakers Shoes For Men's An...   \n",
       "97          Englewood  White Shoes For Men | Casual White Laceups Sho...   \n",
       "98             Bonexy                                   Sneakers For Men   \n",
       "99             Bonexy                                   Sneakers For Men   \n",
       "\n",
       "   Price Discount %  \n",
       "0   ₹799    60% off  \n",
       "1   ₹798    46% off  \n",
       "2   ₹499    72% off  \n",
       "3   ₹379    62% off  \n",
       "4   ₹474    76% off  \n",
       "..   ...        ...  \n",
       "95  ₹258    48% off  \n",
       "96  ₹384    61% off  \n",
       "97  ₹496    66% off  \n",
       "98  ₹426    57% off  \n",
       "99  ₹379    62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the Calling Function\n",
    "\n",
    "flip_sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be\n",
    "done through code only and there should not be any manual step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "def shoes_myntra(url):\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome(r'C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    brand_name=[]\n",
    "    description=[]\n",
    "    product_price=[]\n",
    "    \n",
    "    #apply filter for price\n",
    "    driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #apply filter for colour\n",
    "    driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #scrape the data\n",
    "    j=0\n",
    "    while j<2:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        brands=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "        for q in brands:\n",
    "            brand_name.append(q.text)\n",
    "        \n",
    "        descs=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "        for q in descs:\n",
    "            description.append(q.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "        for q in prices:\n",
    "            product_price.append(q.text)\n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()    \n",
    "        time.sleep(5)\n",
    "        j+=1\n",
    "    \n",
    "    #create a DataFrame for our data\n",
    "    myntra_shoes=pd.DataFrame({})\n",
    "    myntra_shoes['Brand of the Shoes']=brand_name[0:100]\n",
    "    myntra_shoes['Short Shoes Description']=description[0:100]\n",
    "    myntra_shoes['Price of the Shoes']=product_price[0:100]\n",
    "    return myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoes Description</th>\n",
       "      <th>Price of the Shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Heeled Boots</td>\n",
       "      <td>Rs. 11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX VOLLEY Tennis</td>\n",
       "      <td>Rs. 6965Rs. 8195(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 11470Rs. 13495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX INFINITY 2 Sneaker</td>\n",
       "      <td>Rs. 7050Rs. 8295(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>Rs. 12396Rs. 15495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Textured Oxfords</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 6675Rs. 8900(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men IGNITE Ronin Unrest</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Solid Leather Wedges</td>\n",
       "      <td>Rs. 9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Wedges</td>\n",
       "      <td>Rs. 8490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand of the Shoes         Short Shoes Description  \\\n",
       "0             Saint G            Leather Heeled Boots   \n",
       "1                Nike       Men AIR MAX VOLLEY Tennis   \n",
       "2                Nike      Men AIR ZOOM Running Shoes   \n",
       "3                Nike  Men AIR MAX INFINITY 2 Sneaker   \n",
       "4                Nike      Men React Infinity Running   \n",
       "..                ...                             ...   \n",
       "95       Hush Puppies            Men Textured Oxfords   \n",
       "96            Saint G      Women Leather Heeled Boots   \n",
       "97               Puma         Men IGNITE Ronin Unrest   \n",
       "98               Geox            Solid Leather Wedges   \n",
       "99               Geox              Women Solid Wedges   \n",
       "\n",
       "             Price of the Shoes  \n",
       "0                     Rs. 11800  \n",
       "1     Rs. 6965Rs. 8195(15% OFF)  \n",
       "2   Rs. 11470Rs. 13495(15% OFF)  \n",
       "3     Rs. 7050Rs. 8295(15% OFF)  \n",
       "4   Rs. 12396Rs. 15495(20% OFF)  \n",
       "..                          ...  \n",
       "95                     Rs. 6999  \n",
       "96    Rs. 6675Rs. 8900(25% OFF)  \n",
       "97                     Rs. 6999  \n",
       "98                     Rs. 9490  \n",
       "99                     Rs. 8490  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the Calling Function\n",
    "\n",
    "shoes=shoes_myntra('https://www.myntra.com/shoes')\n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# price and discounted price of the shoes are came under same element id. So splitted the price and discounted price.And create a dataframe with the current price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_myntra=shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the price and the discounted price\n",
    "\n",
    "new_price=shoes_myntra['Price of the Shoes'].str.split(\"Rs.\",n=2,expand=True)\n",
    "shoes_myntra['Price in Rs']=new_price[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the old price column\n",
    "\n",
    "shoes_myntra.drop(columns=('Price of the Shoes'),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoes Description</th>\n",
       "      <th>Price in Rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Heeled Boots</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX VOLLEY Tennis</td>\n",
       "      <td>6965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>11470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX INFINITY 2 Sneaker</td>\n",
       "      <td>7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>12396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Textured Oxfords</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men IGNITE Ronin Unrest</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Solid Leather Wedges</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Wedges</td>\n",
       "      <td>8490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand of the Shoes         Short Shoes Description Price in Rs\n",
       "0             Saint G            Leather Heeled Boots       11800\n",
       "1                Nike       Men AIR MAX VOLLEY Tennis        6965\n",
       "2                Nike      Men AIR ZOOM Running Shoes       11470\n",
       "3                Nike  Men AIR MAX INFINITY 2 Sneaker        7050\n",
       "4                Nike      Men React Infinity Running       12396\n",
       "..                ...                             ...         ...\n",
       "95       Hush Puppies            Men Textured Oxfords        6999\n",
       "96            Saint G      Women Leather Heeled Boots        6675\n",
       "97               Puma         Men IGNITE Ronin Unrest        6999\n",
       "98               Geox            Solid Leather Wedges        9490\n",
       "99               Geox              Women Solid Wedges        8490\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_myntra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the Function Definition\n",
    "\n",
    "def laptop(url):\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome('C:/Users/stead/AppData/Local/Temp/Temp1_chromedriver_win32.zip/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    item_title=[]\n",
    "    price=[]\n",
    "    rating=[]\n",
    "    \n",
    "    #search for laptop product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "    driver.find_element_by_xpath('//input[@type=\"submit\"]').click()\n",
    "        \n",
    "    #apply filter for \"Intel Core i7\"\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a',).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #apply filter for \"Intel Core i9\"  \n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()\n",
    "        \n",
    "    #scrape the data\n",
    "    titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for i in titles:\n",
    "        item_title.append(i.text)\n",
    "    prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "    for i in ratings:\n",
    "        rating.append(i.get_attribute('aria-label'))\n",
    "        \n",
    "    #create a DataFrame for our data\n",
    "    amazon_laptops=pd.DataFrame({})\n",
    "    amazon_laptops['Title']=item_title[:10]\n",
    "    amazon_laptops['Price']=price[:10]\n",
    "    amazon_laptops['Rating']=rating[:10]\n",
    "    return amazon_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Renewed) HP ZBook 15 G3 Mobile Workstation - ...</td>\n",
       "      <td>1,87,490</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>38,990</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>76,500</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...</td>\n",
       "      <td>5,22,077</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td>40,990</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>53,999</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>2,59,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>83,990</td>\n",
       "      <td>2.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>1,35,490</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>1,98,590</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price  \\\n",
       "0  (Renewed) HP ZBook 15 G3 Mobile Workstation - ...  1,87,490   \n",
       "1  (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...    38,990   \n",
       "2  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...    76,500   \n",
       "3  ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...  5,22,077   \n",
       "4  LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...    40,990   \n",
       "5  Mi Notebook Horizon Edition 14 Intel Core i5-1...    53,999   \n",
       "6  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  2,59,990   \n",
       "7  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    83,990   \n",
       "8  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  1,35,490   \n",
       "9  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  1,98,590   \n",
       "\n",
       "               Rating  \n",
       "0  4.6 out of 5 stars  \n",
       "1  3.9 out of 5 stars  \n",
       "2  3.5 out of 5 stars  \n",
       "3  4.3 out of 5 stars  \n",
       "4  3.3 out of 5 stars  \n",
       "5  5.0 out of 5 stars  \n",
       "6  4.3 out of 5 stars  \n",
       "7  2.7 out of 5 stars  \n",
       "8  4.3 out of 5 stars  \n",
       "9  4.6 out of 5 stars  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the Calling Function\n",
    "\n",
    "laptop('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaishali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
